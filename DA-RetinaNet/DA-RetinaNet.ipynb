{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Detectron2 Installation <br>\n",
        "1) Select the GPU as hardware in the runtime<br>\n",
        "2) Run the following cell.<br>\n",
        "NB: The runtime will be restarted at the end of this installation which requires few minutes.\n"
      ],
      "metadata": {
        "id": "GXhEjILxLg2f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtYj3_gUlTtV"
      },
      "outputs": [],
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "exit(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check the installation\n",
        "The right output running the following cell should be:<br><br>\n",
        "nvcc: NVIDIA (R) Cuda compiler driver<br>\n",
        "Copyright (c) 2005-2020 NVIDIA Corporation<br>\n",
        "Built on Mon_Oct_12_20:09:46_PDT_2020<br>\n",
        "Cuda compilation tools, release 11.1, V11.1.105<br>\n",
        "Build cuda_11.1.TC455_06.29190527_0<br>\n",
        "torch:  1.11 ; cuda:  cu113<br>\n",
        "detectron2: 0.6<br>"
      ],
      "metadata": {
        "id": "9_wvanUINz2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "id": "h7aOqIDSlgdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Environment Setup\n",
        "\n",
        "Replace at the following path ../usr/local/lib/python3.7/dist-packages/detectron2/modeling/meta_arch/ the dense_detector.py script with our dense_detector.py.<br>\n",
        "Do the same for the fpn.py file at the path ../usr/local/lib/python3.7/dist-packages/detectron2/modeling/backbone/<br>\n",
        "Load the dataset in Google Drive and import it running the block below."
      ],
      "metadata": {
        "id": "6eWXy_PdO7bT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "import logging\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "import detectron2.utils.comm as comm\n",
        "from detectron2.checkpoint import DetectionCheckpointer, PeriodicCheckpointer\n",
        "from detectron2.data import MetadataCatalog, build_detection_test_loader, build_detection_train_loader\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2.solver import build_lr_scheduler, build_optimizer\n",
        "from detectron2.utils.events import EventStorage\n",
        "from detectron2.engine import default_argument_parser, default_setup, default_writers, launch\n",
        "import torch, torchvision\n",
        "from detectron2.data.datasets import register_coco_instances, load_coco_json, register_pascal_voc\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FTL7Qu751ddp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Register your Dataset\n",
        "Run the following cell according to your dataset path. <br>\n",
        "If your annotations are in PASCAL VOC use **register_pascal_voc** otherwise **register_coco_instances** if they are in COCO format.\n",
        "\n"
      ],
      "metadata": {
        "id": "VamGIsg3T5q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "register_pascal_voc(\"city_trainS\", \"drive/My Drive/cityscape/\", \"train_s\", 2007, ['car','person','rider','truck','bus','train','motorcycle','bicycle'])\n",
        "register_pascal_voc(\"city_trainT\", \"drive/My Drive/cityscape/\", \"train_t\", 2007, ['car','person','rider','truck','bus','train','motorcycle','bicycle'])\n",
        "\n",
        "register_pascal_voc(\"city_testT\", \"drive/My Drive/cityscape/\", \"test_t\", 2007, ['car','person','rider','truck','bus','train','motorcycle','bicycle'])"
      ],
      "metadata": {
        "id": "80n1N7hkQ2xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This block is an example of how you should use this API\n",
        "register_coco_instances(\"dataset_train_synthetic\", {}, \"drive/My Drive/Bellomo_Dataset_UDA/synthetic/Object_annotations/Training_annotations.json\", \"./drive/My Drive/Bellomo_Dataset_UDA/synthetic/images\")\n",
        "register_coco_instances(\"dataset_train_real\", {}, \"drive/My Drive/Bellomo_Dataset_UDA/real_hololens/training/training_set.json\", \"./drive/My Drive/Bellomo_Dataset_UDA/real_hololens/training\")\n",
        "\n",
        "register_coco_instances(\"dataset_test_real\", {}, \"drive/My Drive/Bellomo_Dataset_UDA/real_hololens/test/test_set.json\", \"./drive/My Drive/Bellomo_Dataset_UDA/real_hololens/test\")"
      ],
      "metadata": {
        "id": "isDeFPTOU9GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Loop Definition\n",
        "Run the following block"
      ],
      "metadata": {
        "id": "_1GhaNx9Ur0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger(\"detectron2\")\n",
        "\n",
        "def do_train(cfg_source, cfg_target, model, resume = False):\n",
        "    print(model)\n",
        "    model.train()\n",
        "    optimizer = build_optimizer(cfg_source, model)\n",
        "    scheduler = build_lr_scheduler(cfg_source, optimizer)\n",
        "    checkpointer = DetectionCheckpointer(model, cfg_source.OUTPUT_DIR, optimizer=optimizer, scheduler=scheduler)\n",
        "\n",
        "    start_iter = (checkpointer.resume_or_load(cfg_source.MODEL.WEIGHTS, resume=resume).get(\"iteration\", -1) + 1)\n",
        "    max_iter = cfg_source.SOLVER.MAX_ITER\n",
        "\n",
        "    periodic_checkpointer = PeriodicCheckpointer(checkpointer, cfg_source.SOLVER.CHECKPOINT_PERIOD, max_iter=max_iter)\n",
        "    writers = default_writers(cfg_source.OUTPUT_DIR, max_iter) if comm.is_main_process() else []\n",
        "\n",
        "    i = 1\n",
        "    max_epoch = 41.27 # max iter / min(data_len(data_source, data_target))\n",
        "    current_epoch = 0\n",
        "    data_len = 1502\n",
        "\n",
        "    alpha3 = 0\n",
        "    alpha4 = 0\n",
        "    alpha5 = 0\n",
        "\n",
        "    data_loader_source = build_detection_train_loader(cfg_source)\n",
        "    data_loader_target = build_detection_train_loader(cfg_target)\n",
        "    logger.info(\"Starting training from iteration {}\".format(start_iter))\n",
        "\n",
        "    with EventStorage(start_iter) as storage:\n",
        "        for data_source,data_target, iteration in zip(data_loader_source, data_loader_target, range(start_iter, max_iter)):\n",
        "            storage.iter = iteration\n",
        "\n",
        "            iteration = iteration + 1\n",
        "            if (iteration % data_len) == 0:\n",
        "                current_epoch += 1\n",
        "                i = 1\n",
        "\n",
        "            p = float( i + current_epoch * data_len) / max_epoch / data_len\n",
        "            alpha = 2. / ( 1. + np.exp( -10 * p)) - 1\n",
        "            i += 1\n",
        "\n",
        "            alpha3 = alpha\n",
        "            alpha4 = alpha\n",
        "            alpha5 = alpha\n",
        "\n",
        "            if alpha3 > 0.5:\n",
        "                alpha3 = 0.5\n",
        "\n",
        "            if alpha4 > 0.5:\n",
        "                alpha4 = 0.5\n",
        "\n",
        "            if alpha5 > 0.1:\n",
        "                alpha5 = 0.1\n",
        "\n",
        "            loss_dict = model(data_source, False, alpha3, alpha4, alpha5)\n",
        "            loss_dict_target = model(data_target, True, alpha3, alpha4, alpha5)\n",
        "            loss_dict[\"loss_r3\"] += loss_dict_target[\"loss_r3\"]\n",
        "            loss_dict[\"loss_r4\"] += loss_dict_target[\"loss_r4\"]\n",
        "            loss_dict[\"loss_r5\"] += loss_dict_target[\"loss_r5\"]\n",
        "\n",
        "            loss_dict[\"loss_r3\"] *= 0.5\n",
        "            loss_dict[\"loss_r4\"] *= 0.5\n",
        "            loss_dict[\"loss_r5\"] *= 0.5\n",
        "            losses = sum(loss_dict.values())\n",
        "            assert torch.isfinite(losses).all(), loss_dict\n",
        "\n",
        "            loss_dict_reduced = {k: v.item() for k, v in comm.reduce_dict(loss_dict).items()}\n",
        "            losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
        "            if comm.is_main_process():\n",
        "                storage.put_scalars(total_loss=losses_reduced, **loss_dict_reduced)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            losses.backward()\n",
        "            optimizer.step()\n",
        "            storage.put_scalar(\"lr\", optimizer.param_groups[0][\"lr\"], smoothing_hint=False)\n",
        "            scheduler.step()\n",
        "\n",
        "            if iteration - start_iter > 5 and ((iteration + 1) % 20 == 0 or iteration == max_iter - 1):\n",
        "                for writer in writers:\n",
        "                    writer.write()\n",
        "            periodic_checkpointer.step(iteration)"
      ],
      "metadata": {
        "id": "55_anon91_GB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Configuration Definition\n",
        "Define the configuration for the source (cfg_source) and target dataset (cfg_target). The cfg_source contains also the parameters which will be used by the network such us: learning rate, number of training iterations, weight decay, number of classes etc...\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xdXrpSs-ZlUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_source = get_cfg()\n",
        "cfg_source.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\"))\n",
        "cfg_source.DATASETS.TRAIN = (\"dataset_train_synthetic\",)\n",
        "cfg_source.DATALOADER.NUM_WORKERS = 4\n",
        "cfg_source.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\")\n",
        "cfg_source.SOLVER.IMS_PER_BATCH = 4\n",
        "cfg_source.SOLVER.BASE_LR = 0.0002\n",
        "cfg_source.SOLVER.WEIGHT_DECAY = 0.001\n",
        "cfg_source.SOLVER.MAX_ITER = 62000\n",
        "cfg_source.SOLVER.STEPS = (30000,)\n",
        "#cfg_source.INPUT.MIN_SIZE_TRAIN = (0,)\n",
        "cfg_source.INPUT.MIN_SIZE_TEST = 0\n",
        "os.makedirs(cfg_source.OUTPUT_DIR, exist_ok=True)\n",
        "cfg_source.MODEL.RETINANET.NUM_CLASSES = 16\n",
        "model = build_model(cfg_source)\n",
        "\n",
        "cfg_target = get_cfg()\n",
        "cfg_target.DATASETS.TRAIN = (\"dataset_train_real\",)\n",
        "#cfg_target.INPUT.MIN_SIZE_TRAIN = (0,)\n",
        "cfg_target.DATALOADER.NUM_WORKERS = 2\n",
        "cfg_target.SOLVER.IMS_PER_BATCH = 2"
      ],
      "metadata": {
        "id": "Mr-cPOgv2UXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "do_train(cfg_source,cfg_target,model)"
      ],
      "metadata": {
        "id": "L8lzkX2g2Xc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evalutate the performance\n",
        "runt the COCOEvaluator if your annotations are in COCO otherwhise run the PascalVOCDetectionEvaluator"
      ],
      "metadata": {
        "id": "0M1rLpXVddJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#COCO evaluation example\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "evaluator = COCOEvaluator(\"dataset_test_real\", cfg_source, False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg_source, \"dataset_test_real\")\n",
        "inference_on_dataset(model, val_loader, evaluator)"
      ],
      "metadata": {
        "id": "Gu8Jp5IJ2w9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PASCAL VOC evaluation\n",
        "from detectron2.evaluation import inference_on_dataset, PascalVOCDetectionEvaluator\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = PascalVOCDetectionEvaluator(\"city_testT\")\n",
        "val_loader = build_detection_test_loader(cfg_source, \"city_testT\")\n",
        "res = inference_on_dataset(model, val_loader, evaluator)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "hV27c_2720hk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
